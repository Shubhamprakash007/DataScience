{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "irJwtgaevkV9"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#deefine path for file\n",
        "#Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle\n",
        "SHERLOCK_FILE = '1661-0.txt'\n",
        "\n",
        "# Read the data\n",
        "with open('1661-0.txt',  encoding='utf-8-sig') as f:\n",
        "    data = f.read()\n",
        "\n",
        "# Convert to lower case and save as a list\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "print(f\"There are {len(corpus)} lines of sonnets\\n\")\n",
        "print(f\"The first 5 lines look like this:\\n\")\n",
        "for i in range(5):\n",
        "  print(corpus[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDp4xgb1wI8G",
        "outputId": "98fb46aa-9c77-4cd4-8f6f-4d74d5302746"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 12249 lines of sonnets\n",
            "\n",
            "The first 5 lines look like this:\n",
            "\n",
            "a scandal in bohemia\n",
            "to sherlock holmes she is always _the_ woman. i have seldom heard him\n",
            "mention her under any other name. in his eyes she eclipses and\n",
            "predominates the whole of her sex. it was not that he felt any emotion\n",
            "akin to love for irene adler. all emotions, and that one particularly,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "Mxx5hLg8wNSh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mBrwcfn4wX1i",
        "outputId": "f1116b5f-6cd6-4526-cc81-f2d82982f82e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a scandal in bohemia'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences(corpus[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eISAw0rZwcsX",
        "outputId": "73bd86e3-647c-4bb8-c654-38d870526a50"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5],\n",
              " [],\n",
              " [564],\n",
              " [1432],\n",
              " [5],\n",
              " [],\n",
              " [1451],\n",
              " [5],\n",
              " [],\n",
              " [],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [1449],\n",
              " [6424],\n",
              " [2549],\n",
              " [521],\n",
              " [7999],\n",
              " [6],\n",
              " [5]]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences([corpus[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIzADB5Zwe1g",
        "outputId": "340d9f35-84ca-446a-e220-bb808d9eee80"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 937, 8, 1016]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences([corpus[0]])[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IGAV0auwhry",
        "outputId": "138840f7-c2aa-40e9-8999-cdfb7d8ac909"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 937, 8, 1016]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: n_gram_seqs\n",
        "def n_gram_seqs(corpus, tokenizer):\n",
        "    \"\"\"\n",
        "    Generates a list of n-gram sequences\n",
        "    \n",
        "    Args:\n",
        "        corpus (list of string): lines of texts to generate n-grams for\n",
        "        tokenizer (object): an instance of the Tokenizer class containing the word-index dictionary\n",
        "    \n",
        "    Returns:\n",
        "        input_sequences (list of int): the n-gram sequences for each line in the corpus\n",
        "    \"\"\"\n",
        "    input_sequences = []\n",
        "    \n",
        "    ### START CODE HERE\n",
        "    for line in corpus:\n",
        "      token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "      for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "    \n",
        "    ### END CODE HERE\n",
        "    \n",
        "    return input_sequences"
      ],
      "metadata": {
        "id": "-J7anNYswj7D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function with one example\n",
        "first_example_sequence = n_gram_seqs([corpus[0]], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for first example look like this:\\n\")\n",
        "first_example_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cj6ZyQAiwnUi",
        "outputId": "712cfcf5-526e-4183-9293-1dcac1d18a98"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram sequences for first example look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 937], [5, 937, 8], [5, 937, 8, 1016]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function with a bigger corpus\n",
        "next_3_examples_sequence = n_gram_seqs(corpus[1:4], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for next 3 examples look like this:\\n\")\n",
        "next_3_examples_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQFqGYOtwqM8",
        "outputId": "96c54290-0339-48ab-c595-4958ba2bb457"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram sequences for next 3 examples look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 132],\n",
              " [3, 132, 34],\n",
              " [3, 132, 34, 38],\n",
              " [3, 132, 34, 38, 15],\n",
              " [3, 132, 34, 38, 15, 229],\n",
              " [3, 132, 34, 38, 15, 229, 1],\n",
              " [3, 132, 34, 38, 15, 229, 1, 221],\n",
              " [3, 132, 34, 38, 15, 229, 1, 221, 6],\n",
              " [3, 132, 34, 38, 15, 229, 1, 221, 6, 17],\n",
              " [3, 132, 34, 38, 15, 229, 1, 221, 6, 17, 1673],\n",
              " [3, 132, 34, 38, 15, 229, 1, 221, 6, 17, 1673, 116],\n",
              " [3, 132, 34, 38, 15, 229, 1, 221, 6, 17, 1673, 116, 35],\n",
              " [3392, 37],\n",
              " [3392, 37, 267],\n",
              " [3392, 37, 267, 89],\n",
              " [3392, 37, 267, 89, 90],\n",
              " [3392, 37, 267, 89, 90, 213],\n",
              " [3392, 37, 267, 89, 90, 213, 8],\n",
              " [3392, 37, 267, 89, 90, 213, 8, 14],\n",
              " [3392, 37, 267, 89, 90, 213, 8, 14, 150],\n",
              " [3392, 37, 267, 89, 90, 213, 8, 14, 150, 38],\n",
              " [3392, 37, 267, 89, 90, 213, 8, 14, 150, 38, 4766],\n",
              " [3392, 37, 267, 89, 90, 213, 8, 14, 150, 38, 4766, 2],\n",
              " [4767, 1],\n",
              " [4767, 1, 282],\n",
              " [4767, 1, 282, 4],\n",
              " [4767, 1, 282, 4, 37],\n",
              " [4767, 1, 282, 4, 37, 4768],\n",
              " [4767, 1, 282, 4, 37, 4768, 10],\n",
              " [4767, 1, 282, 4, 37, 4768, 10, 12],\n",
              " [4767, 1, 282, 4, 37, 4768, 10, 12, 25],\n",
              " [4767, 1, 282, 4, 37, 4768, 10, 12, 25, 9],\n",
              " [4767, 1, 282, 4, 37, 4768, 10, 12, 25, 9, 11],\n",
              " [4767, 1, 282, 4, 37, 4768, 10, 12, 25, 9, 11, 356],\n",
              " [4767, 1, 282, 4, 37, 4768, 10, 12, 25, 9, 11, 356, 89],\n",
              " [4767, 1, 282, 4, 37, 4768, 10, 12, 25, 9, 11, 356, 89, 1926]]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the n_gram_seqs transformation to the whole corpus\n",
        "input_sequences = n_gram_seqs(corpus, tokenizer)\n",
        "\n",
        "# Save max length \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "print(f\"n_grams of input_sequences have length: {len(input_sequences)}\")\n",
        "print(f\"maximum length of sequences is: {max_sequence_len}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAPzLK2Tws7Q",
        "outputId": "8b68010d-3ede-4500-c120-40700198a63b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_grams of input_sequences have length: 101446\n",
            "maximum length of sequences is: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# GRADED FUNCTION: pad_seqs\n",
        "def pad_seqs(input_sequences, maxlen):\n",
        "    \"\"\"\n",
        "    Pads tokenized sequences to the same length\n",
        "    \n",
        "    Args:\n",
        "        input_sequences (list of int): tokenized sequences to pad\n",
        "        maxlen (int): maximum length of the token sequences\n",
        "    \n",
        "    Returns:\n",
        "        padded_sequences (array of int): tokenized sequences padded to the same length\n",
        "    \"\"\"\n",
        "    ### START CODE HERE\n",
        "    padded_sequences = np.array(pad_sequences(input_sequences, maxlen=maxlen, padding='pre'))\n",
        "    \n",
        "    return padded_sequences\n",
        "    ### END CODE HERE"
      ],
      "metadata": {
        "id": "oGaNSf6Iw4h5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function with the n_grams_seq of the first example\n",
        "first_padded_seq = pad_seqs(first_example_sequence, len(first_example_sequence))\n",
        "first_padded_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvgwW3SgxNF5",
        "outputId": "b5c6612e-a97d-4c35-cafc-0ca3a0bfe98f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    5,  937],\n",
              "       [   5,  937,    8],\n",
              "       [ 937,    8, 1016]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function with the n_grams_seq of the next 3 examples\n",
        "next_3_padded_seq = pad_seqs(next_3_examples_sequence, max([len(s) for s in next_3_examples_sequence]))\n",
        "next_3_padded_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbJM2HXkxRJt",
        "outputId": "6b633ee8-c382-4c84-ea54-cb85e717323d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    3,  132],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           3,  132,   34],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    3,\n",
              "         132,   34,   38],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    3,  132,\n",
              "          34,   38,   15],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    3,  132,   34,\n",
              "          38,   15,  229],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    3,  132,   34,   38,\n",
              "          15,  229,    1],\n",
              "       [   0,    0,    0,    0,    0,    0,    3,  132,   34,   38,   15,\n",
              "         229,    1,  221],\n",
              "       [   0,    0,    0,    0,    0,    3,  132,   34,   38,   15,  229,\n",
              "           1,  221,    6],\n",
              "       [   0,    0,    0,    0,    3,  132,   34,   38,   15,  229,    1,\n",
              "         221,    6,   17],\n",
              "       [   0,    0,    0,    3,  132,   34,   38,   15,  229,    1,  221,\n",
              "           6,   17, 1673],\n",
              "       [   0,    0,    3,  132,   34,   38,   15,  229,    1,  221,    6,\n",
              "          17, 1673,  116],\n",
              "       [   0,    3,  132,   34,   38,   15,  229,    1,  221,    6,   17,\n",
              "        1673,  116,   35],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0, 3392,   37],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "        3392,   37,  267],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 3392,\n",
              "          37,  267,   89],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0, 3392,   37,\n",
              "         267,   89,   90],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0, 3392,   37,  267,\n",
              "          89,   90,  213],\n",
              "       [   0,    0,    0,    0,    0,    0,    0, 3392,   37,  267,   89,\n",
              "          90,  213,    8],\n",
              "       [   0,    0,    0,    0,    0,    0, 3392,   37,  267,   89,   90,\n",
              "         213,    8,   14],\n",
              "       [   0,    0,    0,    0,    0, 3392,   37,  267,   89,   90,  213,\n",
              "           8,   14,  150],\n",
              "       [   0,    0,    0,    0, 3392,   37,  267,   89,   90,  213,    8,\n",
              "          14,  150,   38],\n",
              "       [   0,    0,    0, 3392,   37,  267,   89,   90,  213,    8,   14,\n",
              "         150,   38, 4766],\n",
              "       [   0,    0, 3392,   37,  267,   89,   90,  213,    8,   14,  150,\n",
              "          38, 4766,    2],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0, 4767,    1],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "        4767,    1,  282],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 4767,\n",
              "           1,  282,    4],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0, 4767,    1,\n",
              "         282,    4,   37],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0, 4767,    1,  282,\n",
              "           4,   37, 4768],\n",
              "       [   0,    0,    0,    0,    0,    0,    0, 4767,    1,  282,    4,\n",
              "          37, 4768,   10],\n",
              "       [   0,    0,    0,    0,    0,    0, 4767,    1,  282,    4,   37,\n",
              "        4768,   10,   12],\n",
              "       [   0,    0,    0,    0,    0, 4767,    1,  282,    4,   37, 4768,\n",
              "          10,   12,   25],\n",
              "       [   0,    0,    0,    0, 4767,    1,  282,    4,   37, 4768,   10,\n",
              "          12,   25,    9],\n",
              "       [   0,    0,    0, 4767,    1,  282,    4,   37, 4768,   10,   12,\n",
              "          25,    9,   11],\n",
              "       [   0,    0, 4767,    1,  282,    4,   37, 4768,   10,   12,   25,\n",
              "           9,   11,  356],\n",
              "       [   0, 4767,    1,  282,    4,   37, 4768,   10,   12,   25,    9,\n",
              "          11,  356,   89],\n",
              "       [4767,    1,  282,    4,   37, 4768,   10,   12,   25,    9,   11,\n",
              "         356,   89, 1926]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad the whole corpus\n",
        "input_sequences = pad_seqs(input_sequences, max_sequence_len)\n",
        "\n",
        "print(f\"padded corpus has shape: {input_sequences.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKwA6ks8xTcD",
        "outputId": "1727fdf4-d0e3-42bd-9228-3df00edde181"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padded corpus has shape: (101446, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: features_and_labels\n",
        "def features_and_labels(input_sequences, total_words):\n",
        "    \"\"\"\n",
        "    Generates features and labels from n-grams\n",
        "    \n",
        "    Args:\n",
        "        input_sequences (list of int): sequences to split features and labels from\n",
        "        total_words (int): vocabulary size\n",
        "    \n",
        "    Returns:\n",
        "        features, one_hot_labels (array of int, array of int): arrays of features and one-hot encoded labels\n",
        "    \"\"\"\n",
        "    ### START CODE HERE\n",
        "    features = input_sequences[:,:-1]\n",
        "    labels = input_sequences[:,-1]\n",
        "    one_hot_labels = to_categorical(labels, num_classes=total_words)\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return features, one_hot_labels"
      ],
      "metadata": {
        "id": "aoXoSp3zxYQh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function with the padded n_grams_seq of the first example\n",
        "first_features, first_labels = features_and_labels(first_padded_seq, total_words)\n",
        "\n",
        "print(f\"labels have shape: {first_labels.shape}\")\n",
        "print(\"\\nfeatures look like this:\\n\")\n",
        "first_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3BKgXmhxbxX",
        "outputId": "61c5c5fc-4081-4823-b01d-37bd68754f1f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels have shape: (3, 8916)\n",
            "\n",
            "features look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   5],\n",
              "       [  5, 937],\n",
              "       [937,   8]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the whole corpus\n",
        "features, labels = features_and_labels(input_sequences, total_words)\n",
        "\n",
        "print(f\"features have shape: {features.shape}\")\n",
        "print(f\"labels have shape: {labels.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8WpdBWCxeD-",
        "outputId": "154e485f-9149-4017-eb60-0e5c95985ac2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features have shape: (101446, 19)\n",
            "labels have shape: (101446, 8916)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: create_model\n",
        "def create_model(total_words, max_sequence_len):\n",
        "    \"\"\"\n",
        "    Creates a text generator model\n",
        "    \n",
        "    Args:\n",
        "        total_words (int): size of the vocabulary for the Embedding layer input\n",
        "        max_sequence_len (int): length of the input sequences\n",
        "    \n",
        "    Returns:\n",
        "        model (tf.keras Model): the text generator model\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    ### START CODE HERE\n",
        "    model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "    #model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "    model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
        "    #model.add(Dropout(0.2))\n",
        "    model.add(LSTM(100))\n",
        "    model.add(Dense(total_words/2, activation='relu'))\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    ### END CODE HERE\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "KPKZiyoqxhBT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the untrained model\n",
        "model = create_model(total_words, max_sequence_len)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(features, labels, epochs=50, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaiVOSEnxlOX",
        "outputId": "5c145d73-c811-40a7-f0bf-5dd5bc941aaf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3171/3171 [==============================] - 70s 19ms/step - loss: 6.2842 - accuracy: 0.0639\n",
            "Epoch 2/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 5.7597 - accuracy: 0.0952\n",
            "Epoch 3/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 5.4615 - accuracy: 0.1170\n",
            "Epoch 4/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 5.2410 - accuracy: 0.1291\n",
            "Epoch 5/50\n",
            "3171/3171 [==============================] - 62s 20ms/step - loss: 5.0597 - accuracy: 0.1412\n",
            "Epoch 6/50\n",
            "3171/3171 [==============================] - 63s 20ms/step - loss: 4.9067 - accuracy: 0.1508\n",
            "Epoch 7/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 4.7608 - accuracy: 0.1599\n",
            "Epoch 8/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 4.6269 - accuracy: 0.1671\n",
            "Epoch 9/50\n",
            "3171/3171 [==============================] - 62s 19ms/step - loss: 4.5009 - accuracy: 0.1741\n",
            "Epoch 10/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 4.3768 - accuracy: 0.1815\n",
            "Epoch 11/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 4.2547 - accuracy: 0.1890\n",
            "Epoch 12/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 4.1313 - accuracy: 0.1961\n",
            "Epoch 13/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 4.0066 - accuracy: 0.2054\n",
            "Epoch 14/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 3.8832 - accuracy: 0.2150\n",
            "Epoch 15/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 3.7585 - accuracy: 0.2254\n",
            "Epoch 16/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 3.6368 - accuracy: 0.2376\n",
            "Epoch 17/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 3.5118 - accuracy: 0.2506\n",
            "Epoch 18/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 3.3857 - accuracy: 0.2643\n",
            "Epoch 19/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 3.2631 - accuracy: 0.2791\n",
            "Epoch 20/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 3.1413 - accuracy: 0.2956\n",
            "Epoch 21/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 3.0207 - accuracy: 0.3121\n",
            "Epoch 22/50\n",
            "3171/3171 [==============================] - 60s 19ms/step - loss: 2.8973 - accuracy: 0.3320\n",
            "Epoch 23/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 2.7779 - accuracy: 0.3505\n",
            "Epoch 24/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 2.6605 - accuracy: 0.3700\n",
            "Epoch 25/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 2.5414 - accuracy: 0.3924\n",
            "Epoch 26/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 2.4255 - accuracy: 0.4128\n",
            "Epoch 27/50\n",
            "3171/3171 [==============================] - 60s 19ms/step - loss: 2.3129 - accuracy: 0.4340\n",
            "Epoch 28/50\n",
            "3171/3171 [==============================] - 60s 19ms/step - loss: 2.2001 - accuracy: 0.4563\n",
            "Epoch 29/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 2.0960 - accuracy: 0.4773\n",
            "Epoch 30/50\n",
            "3171/3171 [==============================] - 60s 19ms/step - loss: 1.9890 - accuracy: 0.5010\n",
            "Epoch 31/50\n",
            "3171/3171 [==============================] - 60s 19ms/step - loss: 1.8901 - accuracy: 0.5206\n",
            "Epoch 32/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 1.7941 - accuracy: 0.5416\n",
            "Epoch 33/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 1.7036 - accuracy: 0.5629\n",
            "Epoch 34/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 1.6137 - accuracy: 0.5806\n",
            "Epoch 35/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 1.5333 - accuracy: 0.6011\n",
            "Epoch 36/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 1.4518 - accuracy: 0.6200\n",
            "Epoch 37/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 1.3757 - accuracy: 0.6378\n",
            "Epoch 38/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 1.3048 - accuracy: 0.6551\n",
            "Epoch 39/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 1.2419 - accuracy: 0.6715\n",
            "Epoch 40/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 1.1840 - accuracy: 0.6846\n",
            "Epoch 41/50\n",
            "3171/3171 [==============================] - 60s 19ms/step - loss: 1.1302 - accuracy: 0.6982\n",
            "Epoch 42/50\n",
            "3171/3171 [==============================] - 60s 19ms/step - loss: 1.0696 - accuracy: 0.7124\n",
            "Epoch 43/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 1.0263 - accuracy: 0.7231\n",
            "Epoch 44/50\n",
            "3171/3171 [==============================] - 60s 19ms/step - loss: 0.9789 - accuracy: 0.7349\n",
            "Epoch 45/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 0.9424 - accuracy: 0.7433\n",
            "Epoch 46/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 0.9005 - accuracy: 0.7546\n",
            "Epoch 47/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 0.8658 - accuracy: 0.7638\n",
            "Epoch 48/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 0.8334 - accuracy: 0.7737\n",
            "Epoch 49/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 0.8074 - accuracy: 0.7797\n",
            "Epoch 50/50\n",
            "3171/3171 [==============================] - 61s 19ms/step - loss: 0.7753 - accuracy: 0.7870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the training curves of your model\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "dXOe0JjI76kc",
        "outputId": "e15390e3-7764-4297-f993-853119ab1e78"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_history():\n",
        "  import pickle\n",
        "  from google.colab import files\n",
        "\n",
        "  with open('history.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f)\n",
        "\n",
        "  files.download('history.pkl')\n",
        "\n",
        "download_history()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "bO51ikn_IRmQ",
        "outputId": "006585c8-5f9d-4f64-dd8b-26352940fbb5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_947b4b22-60c7-4d7f-a12f-f01dc082bc80\", \"history.pkl\", 944)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"\"\"His manner was not effusive. It seldom was but he was glad, \n",
        "I think,to see me. With hardly a word spoken, but with a kindly eye, he waved\n",
        "me to an armchair, threw across his case of cigars\"\"\"\n",
        "next_words = 50\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\t# Convert the text into sequences\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\t# Pad the sequences\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t# Get the probabilities of predicting a word\n",
        "\tpredicted = model.predict(token_list, verbose=0)\n",
        "\t# Choose the next word based on the maximum probability\n",
        "\tpredicted = np.argmax(predicted, axis=-1).item()\n",
        "\t# Get the actual word from the word index\n",
        "\toutput_word = tokenizer.index_word[predicted]\n",
        "\t# Append to the current text\n",
        "\tseed_text += \" \" + output_word\n",
        "\n",
        "print(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqowL1N5I9lS",
        "outputId": "e5a9ba2c-9d5e-4dfc-977e-f87556f7f1a8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "His manner was not effusive. It seldom was but he was glad, \n",
            "I think,to see me. With hardly a word spoken, but with a kindly eye, he waved\n",
            "me to an armchair, threw across his case of cigars and indicated a little more with whiskers  he threw himself down upon his face with his lens in his hand and in english remember your promise for an hour which she was not to answer for crueltys article what have that they should make him whether it could ever\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uJV3927rJ6Qf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}